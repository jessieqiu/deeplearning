{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"ex4_train.csv\",index_col = 0) \n",
    "df_test = pd.read_csv(\"ex4_test.csv\",index_col = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1    2    3    4    5    6    7    8    9 ...  391  392  393  394  \\\n",
       "2240  0  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "4253  0  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "4263  0  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "57    0  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "4788  0  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      395  396  397  398  399  y  \n",
       "2240  0.0  0.0  0.0  0.0    0  4  \n",
       "4253  0.0  0.0  0.0  0.0    0  8  \n",
       "4263  0.0  0.0  0.0  0.0    0  8  \n",
       "57    0.0  0.0  0.0  0.0    0  0  \n",
       "4788  0.0  0.0  0.0  0.0    0  9  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 400) (3500, 1)\n"
     ]
    }
   ],
   "source": [
    "#split training data\n",
    "size = df_train.shape[0]\n",
    "x = df_train.iloc[:,0:400]\n",
    "x_data = x.values\n",
    "y = df_train.iloc[:,-1:]\n",
    "y_data = y.values\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 400) (1500, 1)\n"
     ]
    }
   ],
   "source": [
    "#split test data\n",
    "size2 = df_test.shape[0]\n",
    "x_test = df_test.iloc[:,0:400]\n",
    "x_test = x_test.values\n",
    "y_test = df_test.iloc[:,-1:]\n",
    "y_test = y_test.values\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(y):\n",
    "    if(y.shape[1]!=1):\n",
    "        print('input is wrong');\n",
    "        return -1\n",
    "    length = y.shape[0]\n",
    "    output = np.zeros((10,length))       \n",
    "    for i in range(length):         \n",
    "        if(y[i][0]>9):\n",
    "            #to prevent index out of bound\n",
    "            print('label is wrong');\n",
    "            return -1\n",
    "        else:\n",
    "            output[y[i][0]][i]=1   \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3500)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = one_hot_encoding(y_data)\n",
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, w1, w2, w3, b1, b2, b3, keep_prob):\n",
    "   \n",
    "    hidden_1 = tf.nn.relu(tf.add(tf.matmul(w1,tf.transpose(x)), b1))   \n",
    "    drop_out_1 = tf.nn.dropout(hidden_1, keep_prob, seed=0)      \n",
    "    hidden_2 = tf.nn.relu(tf.add(tf.matmul(w2, drop_out_1), b2))   \n",
    "    drop_out_2 = tf.nn.dropout(hidden_2, keep_prob, seed=0)   \n",
    "    last_layer = tf.nn.sigmoid(tf.add(tf.matmul(w3, drop_out_2) , b3))    \n",
    "    return last_layer\n",
    "\n",
    "\n",
    "def predict(x, w1, w2, w3, b1, b2, b3):    \n",
    "    hidden_1 = tf.nn.relu(tf.add(tf.matmul(w1,tf.transpose(x)), b1))     \n",
    "    hidden_2 = tf.nn.relu(tf.add(tf.matmul(w2, hidden_1), b2))     \n",
    "    last_layer = tf.nn.sigmoid(tf.add(tf.matmul(w3, hidden_2) , b3))   \n",
    "    return last_layer\n",
    "    \n",
    "\n",
    "def initialization(neurons):    \n",
    "    W1 = tf.get_variable( name=\"w_1\", shape=[neurons[0],400], initializer=tf.contrib.layers.xavier_initializer(uniform=False,seed=0,dtype=tf.float32))\n",
    "    W2 = tf.get_variable( name=\"w_2\", shape=[neurons[1],neurons[0]], initializer=tf.contrib.layers.xavier_initializer(uniform=False,seed=0,dtype=tf.float32))\n",
    "    W3 = tf.get_variable( name=\"w_3\", shape=[neurons[2],neurons[1]], initializer=tf.contrib.layers.xavier_initializer(uniform=False,seed=0,dtype=tf.float32))\n",
    "    b1 = tf.get_variable( name=\"b_1\", shape=[neurons[0],1], initializer=tf.contrib.layers.xavier_initializer(uniform=False,seed=0,dtype=tf.float32))\n",
    "    b2 = tf.get_variable( name=\"b_2\", shape=[neurons[1],1], initializer=tf.contrib.layers.xavier_initializer(uniform=False,seed=0,dtype=tf.float32))\n",
    "    b3 = tf.get_variable( name=\"b_3\", shape=[neurons[2],1], initializer=tf.contrib.layers.xavier_initializer(uniform=False,seed=0,dtype=tf.float32))\n",
    "    return W1,W2,W3,b1,b2,b3\n",
    "\n",
    "def getACC(y_true,y_pred):      \n",
    "    #print(\"shape\", y_true.shape, y_pred.shape)\n",
    "    count = 0\n",
    "    total = len(y_true)\n",
    "    for i in range(total):\n",
    "        if(y_true[i] != y_pred[i]):\n",
    "            count +=1\n",
    "    #print (\"error count \", count)     \n",
    "    return 1 - count/total       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "max_iteration = 1000\n",
    "X_tensor = tf.placeholder(tf.float32, shape=None, name=\"x_t\")\n",
    "neurons = [300,200,10]\n",
    "w1, w2, w3, b1, b2, b3 = initialization(neurons)\n",
    "keep_rate = tf.placeholder(tf.float32, shape=None, name=\"keep\")\n",
    "rates = np.arange(0.3, 1 , 0.3);\n",
    "pred = model(X_tensor,w1, w2, w3, b1, b2, b3, keep_rate)\n",
    "cross_entropy =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf.transpose(y_one_hot), logits=tf.transpose(pred)))\n",
    "#cross_entropy = tf.losses.softmax_cross_entropy(y_one_hot,pred)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cross_entropy)\n",
    "pre_raw = predict(X_tensor,w1, w2, w3, b1, b2, b3)\n",
    "predictions =  tf.argmax(input=pre_raw, axis=0)\n",
    "#probabilities = tf.nn.softmax(pre_raw, name=\"softmax_tensor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "keep probability:  0.3\n",
      "iteration: 0\n",
      "cost  2.32964\n",
      "train accuracy  0.10371428571428576\n",
      "test accuracy  0.1346666666666667\n",
      "iteration: 100\n",
      "cost  1.60462\n",
      "train accuracy  0.928\n",
      "test accuracy  0.904\n",
      "iteration: 200\n",
      "cost  1.53461\n",
      "train accuracy  0.962\n",
      "test accuracy  0.9193333333333333\n",
      "iteration: 300\n",
      "cost  1.51452\n",
      "train accuracy  0.9768571428571429\n",
      "test accuracy  0.9273333333333333\n",
      "iteration: 400\n",
      "cost  1.50174\n",
      "train accuracy  0.984\n",
      "test accuracy  0.9306666666666666\n",
      "iteration: 500\n",
      "cost  1.49341\n",
      "train accuracy  0.9894285714285714\n",
      "test accuracy  0.9346666666666666\n",
      "iteration: 600\n",
      "cost  1.48918\n",
      "train accuracy  0.9905714285714285\n",
      "test accuracy  0.9359999999999999\n",
      "iteration: 700\n",
      "cost  1.48402\n",
      "train accuracy  0.9917142857142858\n",
      "test accuracy  0.94\n",
      "iteration: 800\n",
      "cost  1.48064\n",
      "train accuracy  0.992\n",
      "test accuracy  0.9386666666666666\n",
      "iteration: 900\n",
      "cost  1.47808\n",
      "train accuracy  0.9931428571428571\n",
      "test accuracy  0.9386666666666666\n",
      "j 0\n",
      "-------------------------------\n",
      "keep probability:  0.6\n",
      "iteration: 0\n",
      "cost  2.31444\n",
      "train accuracy  0.09371428571428575\n",
      "test accuracy  0.10199999999999998\n",
      "iteration: 100\n",
      "cost  1.54023\n",
      "train accuracy  0.9497142857142857\n",
      "test accuracy  0.9173333333333333\n",
      "iteration: 200\n",
      "cost  1.49664\n",
      "train accuracy  0.9794285714285714\n",
      "test accuracy  0.9333333333333333\n",
      "iteration: 300\n",
      "cost  1.48332\n",
      "train accuracy  0.99\n",
      "test accuracy  0.942\n",
      "iteration: 400\n",
      "cost  1.47588\n",
      "train accuracy  0.9928571428571429\n",
      "test accuracy  0.9413333333333334\n",
      "iteration: 500\n",
      "cost  1.47294\n",
      "train accuracy  0.994\n",
      "test accuracy  0.944\n",
      "iteration: 600\n",
      "cost  1.4692\n",
      "train accuracy  0.9948571428571429\n",
      "test accuracy  0.9446666666666667\n",
      "iteration: 700\n",
      "cost  1.46795\n",
      "train accuracy  0.9948571428571429\n",
      "test accuracy  0.944\n",
      "iteration: 800\n",
      "cost  1.4677\n",
      "train accuracy  0.9957142857142857\n",
      "test accuracy  0.9466666666666667\n",
      "iteration: 900\n",
      "cost  1.46713\n",
      "train accuracy  0.9957142857142857\n",
      "test accuracy  0.946\n",
      "j 1\n",
      "-------------------------------\n",
      "keep probability:  0.9\n",
      "iteration: 0\n",
      "cost  2.31947\n",
      "train accuracy  0.09657142857142853\n",
      "test accuracy  0.09399999999999997\n",
      "iteration: 100\n",
      "cost  1.51208\n",
      "train accuracy  0.9614285714285714\n",
      "test accuracy  0.9246666666666666\n",
      "iteration: 200\n",
      "cost  1.48279\n",
      "train accuracy  0.9842857142857143\n",
      "test accuracy  0.9373333333333334\n",
      "iteration: 300\n",
      "cost  1.47438\n",
      "train accuracy  0.9885714285714285\n",
      "test accuracy  0.944\n",
      "iteration: 400\n",
      "cost  1.47182\n",
      "train accuracy  0.99\n",
      "test accuracy  0.9466666666666667\n",
      "iteration: 500\n",
      "cost  1.47012\n",
      "train accuracy  0.9914285714285714\n",
      "test accuracy  0.9453333333333334\n",
      "iteration: 600\n",
      "cost  1.46942\n",
      "train accuracy  0.992\n",
      "test accuracy  0.9446666666666667\n",
      "iteration: 700\n",
      "cost  1.46895\n",
      "train accuracy  0.9922857142857143\n",
      "test accuracy  0.9446666666666667\n",
      "iteration: 800\n",
      "cost  1.46812\n",
      "train accuracy  0.9925714285714285\n",
      "test accuracy  0.9453333333333334\n",
      "iteration: 900\n",
      "cost  1.46781\n",
      "train accuracy  0.9934285714285714\n",
      "test accuracy  0.944\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "init2 = tf.local_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "session.run(init2)\n",
    "plots = np.zeros((2,len(rates)))\n",
    "\n",
    "for j in range(len(rates)):\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"keep probability: \", rates[j])    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(max_iteration):  \n",
    "        _, loss,p =  session.run([train,cross_entropy,predictions],feed_dict = {X_tensor:x_data,keep_rate:rates[j]})    \n",
    "        if(i%100==0):\n",
    "            print(\"iteration:\", i)        \n",
    "            print(\"cost \", loss)\n",
    "            acc = getACC(y_data, p)\n",
    "            print(\"train accuracy \", acc)\n",
    "            p_test = session.run(predictions,feed_dict = {X_tensor:x_test})\n",
    "            acc_test = getACC(y_test, p_test)\n",
    "            print(\"test accuracy \", acc_test)\n",
    "    plots[0][j] =  acc\n",
    "    plots[1][j] =  acc_test\n",
    "    if(j<len(rates)-1):        \n",
    "        tf.reset_default_graph()         \n",
    "        session.run(init)\n",
    "        session.run(init2)\n",
    "        w1, w2, w3, b1, b2, b3 = initialization(neurons)\n",
    "\n",
    "        \n",
    "print(\"done\")  \n",
    "session.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZAMiDB3FOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bc29467550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( rates, plots[0], marker='', color='skyblue', linewidth=2, label=\"train accuracy\")\n",
    "plt.plot( rates, plots[1], marker='', color='olive', linewidth=2, label=\"test accuracy\")\n",
    "plt.legend()\n",
    "plt.title('accuracy vs keep probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
